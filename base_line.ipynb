{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-08-25T06:55:00.664988Z",
     "start_time": "2024-08-25T06:55:00.655987Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from encoding_function import low_frequency_to_others\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ],
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 데이터 불러오기\n",
    "- 학습: 2023년도 이전\n",
    "- 검증: 2023년\n",
    "- 테스트: 2024년"
   ],
   "id": "612fa091ac8898db"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-25T06:55:01.522125Z",
     "start_time": "2024-08-25T06:55:01.319148Z"
    }
   },
   "cell_type": "code",
   "source": [
    "ROOT_DIR = \"data\"\n",
    "RANDOM_STATE = 999\n",
    "\n",
    "train = pd.read_csv(os.path.join(ROOT_DIR, \"train.csv\"))\n",
    "val = pd.read_csv(os.path.join(ROOT_DIR, \"val.csv\"))\n",
    "test = pd.read_csv(os.path.join(ROOT_DIR, \"test.csv\"))\n",
    "\n",
    "print(train.shape, val.shape)"
   ],
   "id": "fc7baeed3df515e6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48522, 43) (8952, 43)\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 사용하지 않는 feature drop",
   "id": "b85feb78ce70647c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-25T06:55:02.178341Z",
     "start_time": "2024-08-25T06:55:02.157337Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def drop_columns_from_datasets(df):\n",
    "    drop_cols = [\n",
    "        '연도', '회차', '일차', '경주번호',\n",
    "        '금일출주경주',\n",
    "        '모터번호', '전탑승선수1', '전탑승선수2',\n",
    "        '보트번호', '특이사항'\n",
    "    ]\n",
    "\n",
    "    df = df.drop(drop_cols, axis=1)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "train = drop_columns_from_datasets(train)\n",
    "val = drop_columns_from_datasets(val)\n",
    "\n",
    "print(train.shape, val.shape)"
   ],
   "id": "c8e70aede39457c4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48522, 33) (8952, 33)\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 일부 숫자형 변수 변환",
   "id": "d9b5a5c06231b8d3"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "- 코스별 성적/경기수 분리",
   "id": "415d3de999d33ce9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-25T06:55:03.385001Z",
     "start_time": "2024-08-25T06:55:02.759467Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def separation_course(df):\n",
    "    col_list = [\n",
    "        '코스_1코스', '코스_2코스', '코스_3코스', '코스_4코스', '코스_5코스', '코스_6코스'\n",
    "    ]\n",
    "    for col in col_list:\n",
    "        df[[f'{col[3:]}_성적', f'{col[3:]}_경기수']] = df[col].fillna('').str.split('/', expand=True)\n",
    "\n",
    "    df.drop(col_list, axis=1, inplace=True)\n",
    "\n",
    "    return df\n",
    "        \n",
    "\n",
    "\n",
    "train = separation_course(train)\n",
    "val = separation_course(val)\n",
    "\n",
    "print(train.shape, val.shape)"
   ],
   "id": "4de76893ce9cd206",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48522, 39) (8952, 39)\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "- 코스별 성적 스무딩",
   "id": "82e3ad637e2d6e7a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-25T06:55:03.511617Z",
     "start_time": "2024-08-25T06:55:03.387002Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def apply_laplace_smoothing(df, col, global_mean, alpha):\n",
    "    # 경기수 0인 값이 너무 높게 나오는 경향이 있어 분모에 상수 1 추가(없애도 됨)\n",
    "    encoded_value = (df[f'{col}_성적'] * df[f'{col}_경기수'] + global_mean * alpha) / (1 + df[f'{col}_경기수'] + alpha)\n",
    "    df[f'{col}_성적'] = encoded_value\n",
    "\n",
    "    return df\n",
    "\n",
    "def laplace_smoothing_to_course(train, val=None, alpha=1):\n",
    "    col_list = [\n",
    "        '1코스', '2코스', '3코스', '4코스', '5코스', '6코스'\n",
    "    ]\n",
    "    for col in col_list:\n",
    "        train[f'{col}_성적'] = train[f'{col}_성적'].astype(float)\n",
    "        train[f'{col}_경기수'] = train[f'{col}_경기수'].astype(float)\n",
    "        if val is not None:\n",
    "            val[f'{col}_성적'] = val[f'{col}_성적'].astype(float)\n",
    "            val[f'{col}_경기수'] = val[f'{col}_경기수'].astype(float)\n",
    "\n",
    "    # Train 데이터에서 글로벌 평균 계산\n",
    "    global_means = {col: train[f'{col}_성적'].mean() for col in col_list}\n",
    "\n",
    "    for col in col_list:\n",
    "        # Train 데이터에 라플라스 스무딩 적용\n",
    "        train = apply_laplace_smoothing(train, col, global_means[col], alpha)\n",
    "        train.drop(f'{col}_경기수', axis=1, inplace=True)\n",
    "\n",
    "    if val is not None:\n",
    "        for col in col_list:\n",
    "            # Validation 데이터에 Train에서 구한 글로벌 평균으로 라플라스 스무딩 적용\n",
    "            val = apply_laplace_smoothing(val, col, global_means[col], alpha)\n",
    "            val.drop(f'{col}_경기수', axis=1, inplace=True)\n",
    "\n",
    "    if val is not None:\n",
    "        return train, val\n",
    "    else:\n",
    "        return train\n",
    "\n",
    "\n",
    "train, val = laplace_smoothing_to_course(train, val, alpha=1) # 알파가 작을수록 빈도수에 가깝세, 알파가 클수록 전체 평균에 가깝게\n",
    "print(train.shape, val.shape)"
   ],
   "id": "4e8a7b127859206e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48522, 33) (8952, 33)\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "- 최근 8경기 착순 분리",
   "id": "17ddaf712ca4ed32"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-25T06:55:03.733480Z",
     "start_time": "2024-08-25T06:55:03.593646Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def split_last_eight_rank(df):\n",
    "    for i in range(0, 4):\n",
    "        df[f'최근{i+1}경기_착순'] = df['최근8경주_착순'].str[i]\n",
    "    for j in range(5, 9):\n",
    "        df[f'최근{j}경기_착순'] = df['최근8경주_착순'].str[j]\n",
    "        \n",
    "    df.drop('최근8경주_착순', axis=1, inplace=True)\n",
    "        \n",
    "    return df\n",
    "\n",
    "def adjust_for_top3(df):\n",
    "    col_list = [\n",
    "        '최근1경기_착순', '최근2경기_착순', '최근3경기_착순', '최근4경기_착순',\n",
    "        '최근5경기_착순', '최근6경기_착순', '최근7경기_착순', '최근8경기_착순'\n",
    "    ]\n",
    "    \n",
    "    for col in col_list:\n",
    "    # 순위가 1, 2, 3이 아닌 경우, 결측인 경우, 6으로 조정\n",
    "    # (일반화된 성능을 위해 + 3등내에 드는게 중요)\n",
    "        df[col] = df[col].apply(lambda x: x if x in ['1', '2', '3'] else '6')\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "train = split_last_eight_rank(train)\n",
    "train = adjust_for_top3(train)\n",
    "\n",
    "val = split_last_eight_rank(val)\n",
    "val = adjust_for_top3(val)\n",
    "\n",
    "print(train.shape, val.shape)"
   ],
   "id": "8e7e8cb08b1e4754",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48522, 40) (8952, 40)\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 범주형 변수 확인\n",
   "id": "1e1b83cff7de2bbc"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-25T06:55:04.031774Z",
     "start_time": "2024-08-25T06:55:03.985614Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def cal_cat_cols(train, val=None):\n",
    "    num_features = []\n",
    "    objective_cols = []\n",
    "\n",
    "    # 특정 문자열이 포함된 열을 범주형 변수로 지정\n",
    "    word_list = ['번호', '기수', '경기_착순', 'Race_ID']\n",
    "    for col in train.columns:\n",
    "        if any(sub in col for sub in word_list):\n",
    "            objective_cols.append(col)\n",
    "            train[col] = train[col].astype('str')\n",
    "            if val is not None:\n",
    "                val[col] = val[col].astype('str')\n",
    "\n",
    "    # 나머지 열에 대해 숫자형 변환 시도\n",
    "    for col in train.columns:\n",
    "        if col in objective_cols:\n",
    "            continue  # 이미 범주형으로 처리된 열은 제외\n",
    "        try:\n",
    "            # 'float' 타입으로 변환 시도\n",
    "            train[col] = train[col].astype('float')\n",
    "            if val is not None:\n",
    "                val[col] = val[col].astype('float')\n",
    "            num_features.append(col)\n",
    "        except:\n",
    "            objective_cols.append(col)\n",
    "\n",
    "    cat_features = list(set(objective_cols) - set(['rank', 'Race_ID']))\n",
    "\n",
    "    return num_features, cat_features\n",
    "\n",
    "\n",
    "num_features, cat_features = cal_cat_cols(train, val)\n",
    "cat_features"
   ],
   "id": "b470c2d63ca13d5b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['최근6경기_착순',\n",
       " '등급',\n",
       " '기수',\n",
       " '성별',\n",
       " '최근1경기_착순',\n",
       " '최근4경기_착순',\n",
       " '최근8경기_착순',\n",
       " '전일성적',\n",
       " '번호',\n",
       " '선수명',\n",
       " 'FL',\n",
       " '최근2경기_착순',\n",
       " '최근3경기_착순',\n",
       " '최근5경기_착순',\n",
       " '최근7경기_착순']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "- 낮은 빈도 데이터 통합",
   "id": "1c7bfe339b717742"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-25T06:55:42.161740Z",
     "start_time": "2024-08-25T06:55:41.775502Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def low_to_others(train, val, threshold=5):\n",
    "    _, cat_features = cal_cat_cols(train, val)\n",
    "\n",
    "    for col in cat_features:\n",
    "        unifier = low_frequency_to_others(threshold=threshold, verbose=False)\n",
    "        train[col] = unifier.fit_transform(train[col])\n",
    "        val[col] = unifier.transform(val[col])\n",
    "\n",
    "    return train, val\n",
    "\n",
    "train, val = low_to_others(train, val)"
   ],
   "id": "7a708c9445925326",
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## X, y 분리",
   "id": "d6f40188a0734870"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-25T06:55:45.071951Z",
     "start_time": "2024-08-25T06:55:45.046946Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def add_y(df, target='연승', is_train=True):\n",
    "    df['rank'] = df['rank'].replace(0, 6)\n",
    "    df['target'] = 0\n",
    "    \n",
    "    if is_train:\n",
    "        if target=='단승': # 1등여부\n",
    "            condition_target = df['rank'] <= 1\n",
    "        elif target=='연승':\n",
    "            condition_target = df['rank'] <= 2\n",
    "        elif target=='삼복승':\n",
    "            condition_target = df['rank'] <= 3\n",
    "        \n",
    "        df.loc[condition_target, 'target'] = 1\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "train = add_y(train)\n",
    "val = add_y(val)\n",
    "\n",
    "drop_cols = [\n",
    "    '전일성적', 'rank', 'target'\n",
    "]\n",
    "\n",
    "X_train = train.drop(drop_cols, axis=1)\n",
    "y_train = train[['Race_ID', '번호', 'target']]\n",
    "X_val = val.drop(drop_cols, axis=1)\n",
    "y_val = val[['Race_ID', '번호', 'target']]\n",
    "\n",
    "print(X_train.shape, y_train.shape, X_val.shape, y_val.shape)"
   ],
   "id": "de9c342ceb44bb48",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48522, 41) (48522, 3) (8952, 41) (8952, 3)\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-25T06:55:45.557698Z",
     "start_time": "2024-08-25T06:55:45.388448Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def create_player_df(df, player_number):\n",
    "    df['번호'] = df['번호'].astype('float')\n",
    "    player_df = df[df['번호'] == player_number].copy()\n",
    "    player_df.drop('번호', axis=1, inplace=True)\n",
    "\n",
    "    # 컬럼명에 선수 번호를 추가\n",
    "    new_columns = {col: f'{col}_{player_number}번선수' for col in player_df.columns if col != 'Race_ID'}\n",
    "    player_df.rename(columns=new_columns, inplace=True)\n",
    "\n",
    "    # 'Race_ID' 컬럼만 유지하고 나머지는 선수 번호가 붙은 컬럼으로 변경\n",
    "    player_df = player_df[['Race_ID'] + list(new_columns.values())]\n",
    "\n",
    "    return player_df\n",
    "\n",
    "def merge_all_players(df):\n",
    "    merged_df = None\n",
    "\n",
    "    for player_number in range(1, 7):\n",
    "        player_df = create_player_df(df, player_number)\n",
    "\n",
    "        if merged_df is None:\n",
    "            merged_df = player_df\n",
    "        else:\n",
    "            merged_df = pd.merge(merged_df, player_df, on='Race_ID', how='inner')\n",
    "            \n",
    "    merged_df.drop('Race_ID', axis=1, inplace=True)\n",
    "\n",
    "    return merged_df\n",
    "\n",
    "X_train_merged = merge_all_players(X_train)\n",
    "y_train_merged = merge_all_players(y_train)\n",
    "\n",
    "X_val_merged = merge_all_players(X_val)\n",
    "y_val_merged = merge_all_players(y_val)\n",
    "\n",
    "\n",
    "print(X_train_merged.shape, y_train_merged.shape, X_val_merged.shape, y_val_merged.shape)"
   ],
   "id": "4a4168a133beb7ac",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8087, 234) (8087, 6) (1492, 234) (1492, 6)\n"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-25T06:55:47.319905Z",
     "start_time": "2024-08-25T06:55:45.760621Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def all_precoess(train, val, is_train=True):\n",
    "    RANDOM_STATE = 999\n",
    "    \n",
    "    train = drop_columns_from_datasets(train)\n",
    "    val = drop_columns_from_datasets(val)\n",
    "\n",
    "    train = separation_course(train)\n",
    "    val = separation_course(val)\n",
    "\n",
    "    train, val = laplace_smoothing_to_course(train, val, alpha=1)\n",
    "\n",
    "    train = split_last_eight_rank(train)\n",
    "    train = adjust_for_top3(train)\n",
    "    \n",
    "    val = split_last_eight_rank(val)\n",
    "    val = adjust_for_top3(val)\n",
    "\n",
    "    # train, val = low_to_others(train, val)\n",
    "\n",
    "    if is_train:\n",
    "        train = add_y(train, target='단승')\n",
    "        val = add_y(val, target='단승')\n",
    "    else:\n",
    "        train = add_y(train, target='단승', is_train=False)\n",
    "        val = add_y(val, target='단승', is_train=False)\n",
    "\n",
    "    drop_cols = [\n",
    "        '전일성적', 'rank', 'target'\n",
    "    ]\n",
    "    X_train = train.drop(drop_cols, axis=1)\n",
    "    y_train = train[['Race_ID', '번호', 'target']]\n",
    "    X_val = val.drop(drop_cols, axis=1)\n",
    "    y_val = val[['Race_ID', '번호', 'target']]\n",
    "\n",
    "\n",
    "    X_train_merged = merge_all_players(X_train)\n",
    "    y_train_merged = merge_all_players(y_train)\n",
    "    \n",
    "    X_val_merged = merge_all_players(X_val)\n",
    "    y_val_merged = merge_all_players(y_val)\n",
    "    \n",
    "\n",
    "    X_train_merged, X_val_merged = low_to_others(X_train_merged, X_val_merged, threshold=5)\n",
    "    \n",
    "    return X_train_merged, y_train_merged, X_val_merged, y_val_merged\n",
    "\n",
    "\n",
    "train = pd.read_csv(os.path.join(ROOT_DIR, \"train.csv\"))\n",
    "val = pd.read_csv(os.path.join(ROOT_DIR, \"val.csv\"))\n",
    "\n",
    "X_train, y_train, X_val, y_val = all_precoess(train, val, is_train=True)\n",
    "\n",
    "print(X_train.shape, y_train.shape, X_val.shape, y_val.shape)"
   ],
   "id": "e383d255c53505cc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8087, 216) (8087, 6) (1492, 216) (1492, 6)\n"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-25T07:00:04.479596Z",
     "start_time": "2024-08-25T07:00:01.956832Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import numpy as np\n",
    "\n",
    "# CatBoostClassifier를 기본 분류기로 사용하여 MultiOutputClassifier 초기화\n",
    "catboost_base = CatBoostClassifier(\n",
    "    iterations=1000,\n",
    "    learning_rate=0.1,\n",
    "    loss_function='Logloss',\n",
    "    verbose=500,\n",
    "    thread_count = 3\n",
    ")\n",
    "\n",
    "multi_target_model = MultiOutputClassifier(catboost_base, n_jobs=4) # 모델의 코어와 MultiOutputClassifier를 적절히 분배하면 빠름\n",
    "\n",
    "# 모델 학습\n",
    "multi_target_model.fit(X_train, y_train)\n",
    "\n",
    "# 예측 수행\n",
    "y_train_pred = multi_target_model.predict(X_train)\n",
    "y_val_pred = multi_target_model.predict(X_val)\n",
    "\n",
    "# 성능 평가\n",
    "for i in range(y_train.shape[1]):\n",
    "    print(f\"Label {i+1} - Train Accuracy: {accuracy_score(y_train[:, i], y_train_pred[:, i])}\")\n",
    "    print(f\"Label {i+1} - Validation Accuracy: {accuracy_score(y_val[:, i], y_val_pred[:, i])}\")\n",
    "    print(f\"Label {i+1} - Validation F1 Score: {f1_score(y_val[:, i], y_val_pred[:, i], average='weighted')}\")\n"
   ],
   "id": "607c5cda9d3e1a07",
   "outputs": [
    {
     "ename": "CatBoostError",
     "evalue": "Bad value for num_feature[non_default_doc_idx=0,feature_idx=0]=\"A1\": Cannot convert 'b'A1'' to float",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31m_RemoteTraceback\u001B[0m                          Traceback (most recent call last)",
      "\u001B[1;31m_RemoteTraceback\u001B[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"_catboost.pyx\", line 2383, in _catboost.get_float_feature\n  File \"_catboost.pyx\", line 1188, in _catboost._FloatOrNan\n  File \"_catboost.pyx\", line 983, in _catboost._FloatOrNanFromString\nTypeError: Cannot convert 'b'A1'' to float\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"C:\\Users\\eunhak\\anaconda3\\envs\\aimers\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 463, in _process_worker\n    r = call_item()\n  File \"C:\\Users\\eunhak\\anaconda3\\envs\\aimers\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 291, in __call__\n    return self.fn(*self.args, **self.kwargs)\n  File \"C:\\Users\\eunhak\\anaconda3\\envs\\aimers\\lib\\site-packages\\joblib\\parallel.py\", line 598, in __call__\n    return [func(*args, **kwargs)\n  File \"C:\\Users\\eunhak\\anaconda3\\envs\\aimers\\lib\\site-packages\\joblib\\parallel.py\", line 598, in <listcomp>\n    return [func(*args, **kwargs)\n  File \"C:\\Users\\eunhak\\anaconda3\\envs\\aimers\\lib\\site-packages\\sklearn\\utils\\parallel.py\", line 136, in __call__\n    return self.function(*args, **kwargs)\n  File \"C:\\Users\\eunhak\\anaconda3\\envs\\aimers\\lib\\site-packages\\sklearn\\multioutput.py\", line 67, in _fit_estimator\n    estimator.fit(X, y, **fit_params)\n  File \"C:\\Users\\eunhak\\anaconda3\\envs\\aimers\\lib\\site-packages\\catboost\\core.py\", line 5220, in fit\n    self._fit(X, y, cat_features, text_features, embedding_features, None, sample_weight, None, None, None, None, baseline, use_best_model,\n  File \"C:\\Users\\eunhak\\anaconda3\\envs\\aimers\\lib\\site-packages\\catboost\\core.py\", line 2385, in _fit\n    train_params = self._prepare_train_params(\n  File \"C:\\Users\\eunhak\\anaconda3\\envs\\aimers\\lib\\site-packages\\catboost\\core.py\", line 2265, in _prepare_train_params\n    train_pool = _build_train_pool(X, y, cat_features, text_features, embedding_features, pairs,\n  File \"C:\\Users\\eunhak\\anaconda3\\envs\\aimers\\lib\\site-packages\\catboost\\core.py\", line 1503, in _build_train_pool\n    train_pool = Pool(X, y, cat_features=cat_features, text_features=text_features, embedding_features=embedding_features, pairs=pairs, weight=sample_weight, group_id=group_id,\n  File \"C:\\Users\\eunhak\\anaconda3\\envs\\aimers\\lib\\site-packages\\catboost\\core.py\", line 848, in __init__\n    self._init(data, label, cat_features, text_features, embedding_features, embedding_features_data, pairs, weight,\n  File \"C:\\Users\\eunhak\\anaconda3\\envs\\aimers\\lib\\site-packages\\catboost\\core.py\", line 1481, in _init\n    self._init_pool(data, label, cat_features, text_features, embedding_features, embedding_features_data, pairs, weight,\n  File \"_catboost.pyx\", line 4159, in _catboost._PoolBase._init_pool\n  File \"_catboost.pyx\", line 4209, in _catboost._PoolBase._init_pool\n  File \"_catboost.pyx\", line 4025, in _catboost._PoolBase._init_features_order_layout_pool\n  File \"_catboost.pyx\", line 2963, in _catboost._set_features_order_data_pd_data_frame\n  File \"_catboost.pyx\", line 2427, in _catboost.create_num_factor_data\n  File \"_catboost.pyx\", line 2385, in _catboost.get_float_feature\n_catboost.CatBoostError: Bad value for num_feature[non_default_doc_idx=0,feature_idx=0]=\"A1\": Cannot convert 'b'A1'' to float\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[1;31mCatBoostError\u001B[0m                             Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[28], line 18\u001B[0m\n\u001B[0;32m     15\u001B[0m multi_target_model \u001B[38;5;241m=\u001B[39m MultiOutputClassifier(catboost_base, n_jobs\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m4\u001B[39m) \u001B[38;5;66;03m# 모델의 코어와 MultiOutputClassifier를 적절히 분배하면 빠름\u001B[39;00m\n\u001B[0;32m     17\u001B[0m \u001B[38;5;66;03m# 모델 학습\u001B[39;00m\n\u001B[1;32m---> 18\u001B[0m \u001B[43mmulti_target_model\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_train\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     20\u001B[0m \u001B[38;5;66;03m# 예측 수행\u001B[39;00m\n\u001B[0;32m     21\u001B[0m y_train_pred \u001B[38;5;241m=\u001B[39m multi_target_model\u001B[38;5;241m.\u001B[39mpredict(X_train)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\aimers\\lib\\site-packages\\sklearn\\multioutput.py:543\u001B[0m, in \u001B[0;36mMultiOutputClassifier.fit\u001B[1;34m(self, X, Y, sample_weight, **fit_params)\u001B[0m\n\u001B[0;32m    517\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mfit\u001B[39m(\u001B[38;5;28mself\u001B[39m, X, Y, sample_weight\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mfit_params):\n\u001B[0;32m    518\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Fit the model to data matrix X and targets Y.\u001B[39;00m\n\u001B[0;32m    519\u001B[0m \n\u001B[0;32m    520\u001B[0m \u001B[38;5;124;03m    Parameters\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    541\u001B[0m \u001B[38;5;124;03m        Returns a fitted instance.\u001B[39;00m\n\u001B[0;32m    542\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m--> 543\u001B[0m     \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39mfit(X, Y, sample_weight\u001B[38;5;241m=\u001B[39msample_weight, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mfit_params)\n\u001B[0;32m    544\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mclasses_ \u001B[38;5;241m=\u001B[39m [estimator\u001B[38;5;241m.\u001B[39mclasses_ \u001B[38;5;28;01mfor\u001B[39;00m estimator \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mestimators_]\n\u001B[0;32m    545\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\aimers\\lib\\site-packages\\sklearn\\base.py:1473\u001B[0m, in \u001B[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001B[1;34m(estimator, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1466\u001B[0m     estimator\u001B[38;5;241m.\u001B[39m_validate_params()\n\u001B[0;32m   1468\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m config_context(\n\u001B[0;32m   1469\u001B[0m     skip_parameter_validation\u001B[38;5;241m=\u001B[39m(\n\u001B[0;32m   1470\u001B[0m         prefer_skip_nested_validation \u001B[38;5;129;01mor\u001B[39;00m global_skip_validation\n\u001B[0;32m   1471\u001B[0m     )\n\u001B[0;32m   1472\u001B[0m ):\n\u001B[1;32m-> 1473\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m fit_method(estimator, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\aimers\\lib\\site-packages\\sklearn\\multioutput.py:278\u001B[0m, in \u001B[0;36m_MultiOutputEstimator.fit\u001B[1;34m(self, X, y, sample_weight, **fit_params)\u001B[0m\n\u001B[0;32m    275\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m sample_weight \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    276\u001B[0m         routed_params\u001B[38;5;241m.\u001B[39mestimator\u001B[38;5;241m.\u001B[39mfit[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msample_weight\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m sample_weight\n\u001B[1;32m--> 278\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mestimators_ \u001B[38;5;241m=\u001B[39m \u001B[43mParallel\u001B[49m\u001B[43m(\u001B[49m\u001B[43mn_jobs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mn_jobs\u001B[49m\u001B[43m)\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    279\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdelayed\u001B[49m\u001B[43m(\u001B[49m\u001B[43m_fit_estimator\u001B[49m\u001B[43m)\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    280\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mestimator\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m[\u001B[49m\u001B[43m:\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mi\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mrouted_params\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mestimator\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\n\u001B[0;32m    281\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    282\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mi\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43mrange\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43my\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mshape\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    283\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    285\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mestimators_[\u001B[38;5;241m0\u001B[39m], \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mn_features_in_\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[0;32m    286\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_features_in_ \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mestimators_[\u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m.\u001B[39mn_features_in_\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\aimers\\lib\\site-packages\\sklearn\\utils\\parallel.py:74\u001B[0m, in \u001B[0;36mParallel.__call__\u001B[1;34m(self, iterable)\u001B[0m\n\u001B[0;32m     69\u001B[0m config \u001B[38;5;241m=\u001B[39m get_config()\n\u001B[0;32m     70\u001B[0m iterable_with_config \u001B[38;5;241m=\u001B[39m (\n\u001B[0;32m     71\u001B[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001B[0;32m     72\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m delayed_func, args, kwargs \u001B[38;5;129;01min\u001B[39;00m iterable\n\u001B[0;32m     73\u001B[0m )\n\u001B[1;32m---> 74\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;21;43m__call__\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43miterable_with_config\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\aimers\\lib\\site-packages\\joblib\\parallel.py:2007\u001B[0m, in \u001B[0;36mParallel.__call__\u001B[1;34m(self, iterable)\u001B[0m\n\u001B[0;32m   2001\u001B[0m \u001B[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001B[39;00m\n\u001B[0;32m   2002\u001B[0m \u001B[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001B[39;00m\n\u001B[0;32m   2003\u001B[0m \u001B[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001B[39;00m\n\u001B[0;32m   2004\u001B[0m \u001B[38;5;66;03m# dispatch of the tasks to the workers.\u001B[39;00m\n\u001B[0;32m   2005\u001B[0m \u001B[38;5;28mnext\u001B[39m(output)\n\u001B[1;32m-> 2007\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m output \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mreturn_generator \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;43mlist\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43moutput\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\aimers\\lib\\site-packages\\joblib\\parallel.py:1650\u001B[0m, in \u001B[0;36mParallel._get_outputs\u001B[1;34m(self, iterator, pre_dispatch)\u001B[0m\n\u001B[0;32m   1647\u001B[0m     \u001B[38;5;28;01myield\u001B[39;00m\n\u001B[0;32m   1649\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backend\u001B[38;5;241m.\u001B[39mretrieval_context():\n\u001B[1;32m-> 1650\u001B[0m         \u001B[38;5;28;01myield from\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_retrieve()\n\u001B[0;32m   1652\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mGeneratorExit\u001B[39;00m:\n\u001B[0;32m   1653\u001B[0m     \u001B[38;5;66;03m# The generator has been garbage collected before being fully\u001B[39;00m\n\u001B[0;32m   1654\u001B[0m     \u001B[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001B[39;00m\n\u001B[0;32m   1655\u001B[0m     \u001B[38;5;66;03m# the user if necessary.\u001B[39;00m\n\u001B[0;32m   1656\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_exception \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\aimers\\lib\\site-packages\\joblib\\parallel.py:1754\u001B[0m, in \u001B[0;36mParallel._retrieve\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1747\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_wait_retrieval():\n\u001B[0;32m   1748\u001B[0m \n\u001B[0;32m   1749\u001B[0m     \u001B[38;5;66;03m# If the callback thread of a worker has signaled that its task\u001B[39;00m\n\u001B[0;32m   1750\u001B[0m     \u001B[38;5;66;03m# triggered an exception, or if the retrieval loop has raised an\u001B[39;00m\n\u001B[0;32m   1751\u001B[0m     \u001B[38;5;66;03m# exception (e.g. `GeneratorExit`), exit the loop and surface the\u001B[39;00m\n\u001B[0;32m   1752\u001B[0m     \u001B[38;5;66;03m# worker traceback.\u001B[39;00m\n\u001B[0;32m   1753\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_aborting:\n\u001B[1;32m-> 1754\u001B[0m         \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_raise_error_fast\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1755\u001B[0m         \u001B[38;5;28;01mbreak\u001B[39;00m\n\u001B[0;32m   1757\u001B[0m     \u001B[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001B[39;00m\n\u001B[0;32m   1758\u001B[0m     \u001B[38;5;66;03m# async callbacks to progress.\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\aimers\\lib\\site-packages\\joblib\\parallel.py:1789\u001B[0m, in \u001B[0;36mParallel._raise_error_fast\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1785\u001B[0m \u001B[38;5;66;03m# If this error job exists, immediately raise the error by\u001B[39;00m\n\u001B[0;32m   1786\u001B[0m \u001B[38;5;66;03m# calling get_result. This job might not exists if abort has been\u001B[39;00m\n\u001B[0;32m   1787\u001B[0m \u001B[38;5;66;03m# called directly or if the generator is gc'ed.\u001B[39;00m\n\u001B[0;32m   1788\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m error_job \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m-> 1789\u001B[0m     \u001B[43merror_job\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_result\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\aimers\\lib\\site-packages\\joblib\\parallel.py:745\u001B[0m, in \u001B[0;36mBatchCompletionCallBack.get_result\u001B[1;34m(self, timeout)\u001B[0m\n\u001B[0;32m    739\u001B[0m backend \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mparallel\u001B[38;5;241m.\u001B[39m_backend\n\u001B[0;32m    741\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m backend\u001B[38;5;241m.\u001B[39msupports_retrieve_callback:\n\u001B[0;32m    742\u001B[0m     \u001B[38;5;66;03m# We assume that the result has already been retrieved by the\u001B[39;00m\n\u001B[0;32m    743\u001B[0m     \u001B[38;5;66;03m# callback thread, and is stored internally. It's just waiting to\u001B[39;00m\n\u001B[0;32m    744\u001B[0m     \u001B[38;5;66;03m# be returned.\u001B[39;00m\n\u001B[1;32m--> 745\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_return_or_raise\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    747\u001B[0m \u001B[38;5;66;03m# For other backends, the main thread needs to run the retrieval step.\u001B[39;00m\n\u001B[0;32m    748\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\aimers\\lib\\site-packages\\joblib\\parallel.py:763\u001B[0m, in \u001B[0;36mBatchCompletionCallBack._return_or_raise\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    761\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m    762\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstatus \u001B[38;5;241m==\u001B[39m TASK_ERROR:\n\u001B[1;32m--> 763\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_result\n\u001B[0;32m    764\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_result\n\u001B[0;32m    765\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n",
      "\u001B[1;31mCatBoostError\u001B[0m: Bad value for num_feature[non_default_doc_idx=0,feature_idx=0]=\"A1\": Cannot convert 'b'A1'' to float"
     ]
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "b6bf42aa889b530b"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
